{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Part 1\n",
    "\n",
    "This notebook contains the script and analysis for part 1 of the assessment 3. This takes the pre-processed data (i.e. output from the \"UK Weather Data Preprocessing Script\" notebook and conducts the relevant pre-processing and analysis relevant for part 1 of assessment 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import datetime\n",
    "\n",
    "os.environ[\"PROJ_LIB\"] = 'C:\\\\Users\\\\angsi\\\\anaconda3\\\\pkgs\\\\proj4-5.2.0-ha925a31_1\\\\Library\\\\share'\n",
    "from mpl_toolkits.basemap import Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "proc_data_path = '..\\proc_data\\weather'\n",
    "weather_df = pd.read_csv(os.path.join(proc_data_path,'weather.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "Check summary statistics of each weather related column for each station, mean, median, standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_cols = ['tmax degC','tmin degC','af days', 'rain mm','sun hours']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in weather_df['station'].unique():\n",
    "    tmp_df = weather_df[weather_df['station'] == station]\n",
    "    # Assign date\n",
    "    tmp_df['date'] = tmp_df.apply(lambda x: datetime.datetime(x['yyyy'], x['mm'], 1), axis = 1)\n",
    "    for weather_var in weather_cols:\n",
    "        plt.figure(figsize = (15,8))\n",
    "        plt.plot(tmp_df['date'],tmp_df[weather_var])\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel(weather_var)\n",
    "        plt.title('Plot of {}: {} Data Over Time'.format(station, weather_var))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the mean does seem to provide a good indication of what might fall within the same cluster\n",
    "weather_df.groupby('station')[weather_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for weather_col in weather_cols:\n",
    "    plt.figure()\n",
    "    weather_df.groupby('station')[weather_col].mean().plot.bar()\n",
    "    plt.title('Mean of {}'.format(weather_col))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficient of variation indicates that af days has more variation (relatively) across years \n",
    "# and it is worth investigating more\n",
    "coeff_var_df = weather_df.groupby('station')[weather_cols].agg(np.std)/weather_df.groupby('station')[weather_cols].agg(np.mean)\n",
    "coeff_var_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for intra-year variation\n",
    "intrayear_cv = weather_df.groupby(['station','yyyy'])[weather_cols].agg(np.std)/weather_df.groupby('station')[weather_cols].agg(np.mean)\n",
    "\n",
    "# Seems like there is still quite a fair of variation intra-year for af days\n",
    "intrayear_cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the standard deviation\n",
    "for weather_col in weather_cols:\n",
    "    plt.figure()\n",
    "    weather_df.groupby('station')[weather_col].std().plot.bar()\n",
    "    plt.title('Standard Deviation of {}'.format(weather_col))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median provides a fairly similar view to the mean\n",
    "weather_df.groupby('station')[weather_cols].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for weather_col in weather_cols:\n",
    "    plt.figure()\n",
    "    weather_df.groupby('station')[weather_col].median().plot.bar()\n",
    "    plt.title('Median of {}'.format(weather_col))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a time series, we should look into monthly data to see how the weather data is like for each station. I think this is a lot more insightful and arguably more affirmative as seasonal changes of weather data would be captured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 999\n",
    "weather_df.groupby(['station','mm'])[weather_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will prepare the average monthly weather data for each station across all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = weather_df.groupby(['station','mm'])[weather_cols].mean().reset_index()\n",
    "\n",
    "X = X.pivot(index='station', columns='mm', values=weather_cols)\n",
    "X.columns = [' '.join([col[0],str(col[1])]).strip() for col in X.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise X before clustering\n",
    "scaler = StandardScaler()\n",
    "X_standardised = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "X_standardised.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "* K-means Clustering\n",
    "* GMM Clustering\n",
    "\n",
    "I start off this section by defining the relevant functions for kmeans clustering, GMM Clustering and plotting function visualise the stations on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clustering(X, max_K):\n",
    "    '''\n",
    "    Takes X and max_K (max number of clusters) does kmeans clustering\n",
    "    Returns the kmeans and inertia list\n",
    "    '''\n",
    "    kmean_lst = []\n",
    "    inertia_lst = []\n",
    "    for k in range(1,max_K):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=1000)\n",
    "        kmeans.fit(X)\n",
    "        inertia_lst.append(kmeans.inertia_)\n",
    "        kmean_lst.append(kmeans)\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(range(1,max_K), inertia_lst)\n",
    "    plt.title('Inertia of the different clusters')\n",
    "    plt.show()\n",
    "        \n",
    "    return kmean_lst, inertia_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_clustering(X, max_K):\n",
    "    '''\n",
    "    Takes X and max_K (max number of clusters) does GMM clustering evaluating based on BIC and silhouette score\n",
    "    Returns the kmeans and inertia list\n",
    "    '''\n",
    "    \n",
    "    # Initialise GMM list, BIC list and silhouette score list\n",
    "    gm_lst = []\n",
    "    bic_lst = []\n",
    "    silhouette_score_lst = []\n",
    "    \n",
    "    for k in range(1,max_K):\n",
    "        \n",
    "        # Fix random seed and fit GMM\n",
    "        gm = GaussianMixture(n_components=k, random_state=0).fit(X)\n",
    "        gm_lst.append(gm)\n",
    "        \n",
    "        # Get the labels\n",
    "        labels = gm.predict(X)\n",
    "        \n",
    "        # Compute BIC and update BIC list\n",
    "        bic_lst.append(gm.bic(X))\n",
    "        \n",
    "        # Compute silhouette score and list\n",
    "        if k == 1:\n",
    "            silhouette_score_lst.append(None)\n",
    "        else:\n",
    "            silhouette_score_lst.append(silhouette_score(X, labels, metric='euclidean'))\n",
    "        \n",
    "    # Plot BIC\n",
    "    plt.figure()\n",
    "    plt.plot(range(1,max_K), bic_lst)\n",
    "    plt.title('BIC Scores')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot Silhouette Score\n",
    "    plt.figure()\n",
    "    plt.plot(range(1,max_K), silhouette_score_lst)\n",
    "    plt.title('Silhouette Scores')\n",
    "    plt.show()\n",
    "    \n",
    "    return gm_lst, bic_lst, silhouette_score_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify what latitude and longitude could be useful for plotting by taking average lat long for the stations\n",
    "weather_df.groupby('station')[['lat','lon']].mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rgba_from_cmap(cmap):\n",
    "    '''\n",
    "    Function to extract rgba from cmap\n",
    "    '''\n",
    "    rgba_lst = []\n",
    "    iteration = 0\n",
    "    while (True):\n",
    "        if iteration == 0:\n",
    "            rgba_lst.append(cmap(iteration))\n",
    "        else:\n",
    "            # When there is no change in cmap we break the while loop\n",
    "            if cmap(iteration) == cmap(iteration-1):\n",
    "                break\n",
    "            else:\n",
    "                rgba_lst.append(cmap(iteration))\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "    return rgba_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ukmap(lat, lon, cluster_labels, station_names):\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    m = Basemap(projection='lcc', resolution='h',\n",
    "                width=0.8E6, height=1.2E6, \n",
    "                lat_0=55, lon_0=-2.7,)\n",
    "    m.etopo(scale=0.9, alpha=0.9)\n",
    "    m.fillcontinents(color=\"#bbe2c6\", lake_color='#c7dbfc')\n",
    "    m.drawmapboundary(fill_color=\"#c7dbfc\")\n",
    "    m.drawcoastlines(color = 'gray')\n",
    "    \n",
    "    # If it goes beyond 17 cluster labels, this function doesn't support it.\n",
    "    if len(np.unique(cluster_labels)) > 17:\n",
    "        print('More than 17 clusters, colours not supported.')\n",
    "        return None\n",
    "    else:\n",
    "        qualcmap1 = matplotlib.cm.get_cmap('Set1')\n",
    "        qualcmap2 = matplotlib.cm.get_cmap('Set2')\n",
    "        cmap_lst = extract_rgba_from_cmap(qualcmap1)\n",
    "        cmap_lst.extend(extract_rgba_from_cmap(qualcmap2))\n",
    "\n",
    "        color_lst = [cmap_lst[cluster_label] for cluster_label in cluster_labels]\n",
    "        x, y = m(lon, lat)\n",
    "        \n",
    "        # Plot points\n",
    "        m.scatter(lon, lat, latlon = True, marker='D',color = color_lst, s = 50, zorder=10)\n",
    "\n",
    "        # Shift it a bit to the right and plot names\n",
    "        for i, station_name in enumerate(station_names):\n",
    "            plt.text(x[i]+20000, y[i], station_name, color = color_lst[i],fontsize = 8)\n",
    "        \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the function\n",
    "plot_ukmap([53.781324], [-2.72], [10], ['Random Point'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean_lst, inertia_lst =kmeans_clustering(X_standardised, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking the number of clusters for K-means clustering\n",
    "Seems like 2 or 4 clusters are the \"elbows\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try 2\n",
    "kmean_lst[1].labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking out the labels for 2 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.index[kmean_lst[1].labels_ == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.index[kmean_lst[1].labels_ == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking out the labels for 4 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmean_lst[3].labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print('Cluster {} includes: {}'.format(i, X.index[labels == i].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for Plotting the K-Means Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the station lat lon data\n",
    "stn_latlon = weather_df[['station','lat','lon']].drop_duplicates().reset_index(drop = True)\n",
    "stn_latlon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the original X with stations\n",
    "X_with_stations = X.reset_index()\n",
    "\n",
    "# Stations with lat lon\n",
    "X_with_stations = pd.merge(X_with_stations, stn_latlon, how= 'left', on = 'station')\n",
    "\n",
    "# Keep only relevant columns for plotting\n",
    "X_with_stations = X_with_stations[['station','lat','lon']]\n",
    "\n",
    "# Assign Cluster Labels\n",
    "X_with_stations['Kmeans 2-Cluster Labels'] = kmean_lst[1].labels_\n",
    "X_with_stations['Kmeans 4-Cluster Labels'] = kmean_lst[3].labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_with_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "plot_ukmap(X_with_stations['lat'].values, X_with_stations['lon'].values, X_with_stations['Kmeans 2-Cluster Labels'].tolist(),\n",
    "          X_with_stations['station'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ukmap(X_with_stations['lat'].values, X_with_stations['lon'].values, X_with_stations['Kmeans 4-Cluster Labels'].tolist(),\n",
    "          X_with_stations['station'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating the same steps for just the average weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ave = weather_df.groupby(['station'])[weather_cols].mean()\n",
    "\n",
    "# Standardise before clustering\n",
    "scaler = StandardScaler()\n",
    "X_ave_standardised = pd.DataFrame(scaler.fit_transform(X_ave), columns = X_ave.columns)\n",
    "\n",
    "kmean_lst_ave, inertia_lst_ave = kmeans_clustering(X_ave_standardised, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmean_lst[3].labels_\n",
    "for i in range(4):\n",
    "    print('Cluster {} includes: {}'.format(i, X_ave.index[labels == i].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the original X with stations\n",
    "X_ave_with_stations = X_ave.reset_index()\n",
    "\n",
    "# Stations with lat lon\n",
    "X_ave_with_stations = pd.merge(X_ave_with_stations, stn_latlon, how= 'left', on = 'station')\n",
    "\n",
    "# Keep only relevant columns for plotting\n",
    "X_ave_with_stations = X_ave_with_stations[['station','lat','lon']]\n",
    "\n",
    "# Assign Cluster Labels\n",
    "X_ave_with_stations['Kmeans 2-Cluster Labels'] = kmean_lst[1].labels_\n",
    "X_ave_with_stations['Kmeans 4-Cluster Labels'] = kmean_lst[3].labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ukmap(X_ave_with_stations['lat'].values, X_ave_with_stations['lon'].values, X_ave_with_stations['Kmeans 2-Cluster Labels'].tolist(),\n",
    "          X_ave_with_stations['station'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ukmap(X_ave_with_stations['lat'].values, X_ave_with_stations['lon'].values, X_ave_with_stations['Kmeans 4-Cluster Labels'].tolist(),\n",
    "          X_ave_with_stations['station'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_lst, bic_lst, silhouette_score_lst =gmm_clustering(X_standardised, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For BIC score, I would take the cluster corresponding to the lowest score and for the silhouette score, the highest. Both metrics point to having 2 clusters in the GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_with_stations['GMM 2-Cluster Labels'] = gm_lst[1].predict(X_standardised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "plot_ukmap(X_with_stations['lat'].values, X_with_stations['lon'].values, X_with_stations['GMM 2-Cluster Labels'].tolist(),\n",
    "          X_with_stations['station'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It yields the same cluster as K-means clustering algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating the exercise with average X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_lst2, bic_lst2, silhouette_score_lst2 =gmm_clustering(X_ave_standardised, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the silouhette score, we still go with 2 clusters but with BIC, we will pick 7 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ave_with_stations['GMM 2-Cluster Labels'] = gm_lst2[1].predict(X_ave_standardised)\n",
    "X_ave_with_stations['GMM 7-Cluster Labels'] = gm_lst2[6].predict(X_ave_standardised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "plot_ukmap(X_ave_with_stations['lat'].values, X_ave_with_stations['lon'].values, X_ave_with_stations['GMM 2-Cluster Labels'].tolist(),\n",
    "          X_ave_with_stations['station'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results\n",
    "plot_ukmap(X_ave_with_stations['lat'].values, X_ave_with_stations['lon'].values, X_ave_with_stations['GMM 7-Cluster Labels'].tolist(),\n",
    "          X_ave_with_stations['station'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these clusters, it does appear that 2-cluster output from K-means algorithm or GMM using the average station monthly weather data provides more interpretable results as it clearly splits clusters data into north and south of UK; and it is more likely for weather to be similar for regions nearer to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
