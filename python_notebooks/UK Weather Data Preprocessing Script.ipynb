{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aberporth.txt',\n",
       " 'armagh.txt',\n",
       " 'ballypatrick.txt',\n",
       " 'bradford.txt',\n",
       " 'braemar.txt',\n",
       " 'camborne.txt',\n",
       " 'cambridge.txt',\n",
       " 'cardiff.txt',\n",
       " 'chivenor.txt',\n",
       " 'cwmystwyth.txt',\n",
       " 'dunstaffnage.txt',\n",
       " 'durham.txt',\n",
       " 'eastbourne.txt',\n",
       " 'eskdalemuir.txt',\n",
       " 'heathrow.txt',\n",
       " 'hurn.txt',\n",
       " 'lerwick.txt',\n",
       " 'leuchars.txt',\n",
       " 'lowestoft.txt',\n",
       " 'manston.txt',\n",
       " 'nairn.txt',\n",
       " 'newtonrigg.txt',\n",
       " 'oxford.txt',\n",
       " 'paisley.txt',\n",
       " 'ringway.txt',\n",
       " 'rossonwye.txt',\n",
       " 'shawbury.txt',\n",
       " 'sheffield.txt',\n",
       " 'southampton.txt',\n",
       " 'stornoway.txt',\n",
       " 'suttonbonington.txt',\n",
       " 'tiree.txt',\n",
       " 'valley.txt',\n",
       " 'waddington.txt',\n",
       " 'whitby.txt',\n",
       " 'wickairport.txt',\n",
       " 'yeovilton.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a path to output obtained data to the weather folder in the raw_data folder\n",
    "raw_data_path = '../raw_data/weather'\n",
    "\n",
    "# Check files in directory\n",
    "weather_file_lst = os.listdir(raw_data_path)\n",
    "weather_file_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL and Data Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lastpos_header(headers_lst, line):\n",
    "    '''\n",
    "    Get the last characters' position in headers_lst in the line\n",
    "    headers_lst (list): list of headers\n",
    "    line (string): the line which contain headers\n",
    "    '''\n",
    "    line_copy = line\n",
    "    \n",
    "    last_pos_lst = []\n",
    "    \n",
    "    for header in headers_lst:\n",
    "        if re.search(header, line_copy) is not None:\n",
    "            pos = re.search(header, line_copy).span()\n",
    "            last_pos = pos[1]\n",
    "            \n",
    "            # Update line by replacing those found with ' '\n",
    "            line_list = list(line_copy)\n",
    "            line_list[pos[0]: pos[1]] = [' ']*(pos[1]-pos[0])\n",
    "            line_copy = ''.join(line_list)\n",
    "            \n",
    "            # Update last_pos_lst\n",
    "            last_pos_lst.append(last_pos)\n",
    "            \n",
    "        else:\n",
    "            print('Unknown Error while processing {}'.format(header))\n",
    "            break\n",
    "            \n",
    "    return last_pos_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_headerlines(header1_lst, header1_lastpos_lst, header2_lst, header2_lastpos_lst):\n",
    "    '''\n",
    "    Function that takes in 4 arguments: header1_lst, header1_lastpos_lst, header2_lst, header2_lastpos_lst\n",
    "    and matches the last positions of the headers in the first header line with the last positions of the headers in the\n",
    "    2nd header line; for those that could be matched, it implies that the header in the 2nd header line actually a wrapped\n",
    "    text from the corresponding header in the first header line. Thus, I concatenate these headers and return them\n",
    "    header1_lst (list): list containing the headers from the first header line\n",
    "    header1_lastpos_lst(list): list containing headers' last positions from the first header line\n",
    "    header2_lst (list): list containing the headers from the 2nd header line\n",
    "    header2_lastpos_lst(list): list containing headers' last positions from the 2nd header line\n",
    "    '''\n",
    "    \n",
    "    for header1_index, header1_lastpos in enumerate(header1_lastpos_lst):\n",
    "        \n",
    "        # Header 2 index match\n",
    "        if header1_lastpos in header2_lastpos_lst:\n",
    "            header2_index_match = header2_lastpos_lst.index(header1_lastpos)\n",
    "\n",
    "            # Clean up the header1\n",
    "            header1_lst[header1_index] = header1_lst[header1_index] + ' ' + header2_lst[header2_index_match]\n",
    "\n",
    "        \n",
    "    return header1_lst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_proc_weather_file(weather_file):\n",
    "    \n",
    "    '''\n",
    "    Loads and processes the weather file after taking the name of the weather file as input\n",
    "    weather_file (string): name of the station's weather data file.\n",
    "    '''\n",
    "    \n",
    "    stn_dir = os.path.join(raw_data_path, weather_file)\n",
    "\n",
    "    with open(stn_dir, 'r') as text_file:\n",
    "        text = text_file.read()\n",
    "        \n",
    "#     print('Loading {}'.format(stn_dir))\n",
    "\n",
    "    # Using the assumption that the first word must be the station name,\n",
    "    # the row corresponding to matches to strings: 'yyyy', 'mm', 'tmax', 'tmin', 'af', 'rain', 'sun' must be the header row\n",
    "    # and that the header row will wrap to the row below.\n",
    "    # Assume that spacing is consistent between one field and next, so the last character's position of each header will match\n",
    "    # the last character's position of the header that has been wrapped to the next line\n",
    "\n",
    "    # Check if first header has been found\n",
    "    header_flag = False\n",
    "\n",
    "    # list to store actual data\n",
    "    actual_data_lst = []\n",
    "    \n",
    "    # Initialise lat, lon\n",
    "    lat, lon = (None, None)\n",
    "\n",
    "    for line_num, line in enumerate(text.splitlines()):\n",
    "\n",
    "            \n",
    "        # Get the longitude and latitude\n",
    "        result = re.findall('Lat (-?\\d+\\.*\\d+) Lon (-?\\d+\\.*\\d*),?\\w?',line)\n",
    "\n",
    "        if len(result) > 0:\n",
    "            lat, lon = result[0]\n",
    "            #print(line)\n",
    "\n",
    "        if header_flag == False:\n",
    "\n",
    "            # Check for header row\n",
    "            header_lst = ['yyyy', 'mm', 'tmax', 'tmin', 'af', 'rain', 'sun']\n",
    "            check = all([header in line for header in header_lst])\n",
    "\n",
    "            if check == True:\n",
    "\n",
    "                # Get header line index\n",
    "                header_line_num = line_num\n",
    "\n",
    "                # Split this by space for this current line\n",
    "                header1 = line.split()\n",
    "\n",
    "                # Get the next line and do this as well\n",
    "                line2 = text.splitlines()[line_num+1]\n",
    "                header2 = line2.split()\n",
    "\n",
    "                # Get the position of last character for each header\n",
    "                header1_lastpos_lst = get_lastpos_header(header1, line)\n",
    "                header2_lastpos_lst = get_lastpos_header(header2, line2)\n",
    "\n",
    "                # Match and combine the headers\n",
    "                combined_header = match_headerlines(header1, header1_lastpos_lst, header2, header2_lastpos_lst)\n",
    "\n",
    "                header_flag = True\n",
    "\n",
    "        else:\n",
    "            # Adjust for 2nd row of headerline\n",
    "            if line_num == header_line_num + 1:\n",
    "                continue\n",
    "            else:\n",
    "                # Update data, keeping only the first few list entries corresponding to the the headers\n",
    "                data = line.split()\n",
    "                data = data[:len(combined_header)]\n",
    "                actual_data_lst.append(data)\n",
    "\n",
    "    # Create a pandas dataframe to store this data\n",
    "    df = pd.DataFrame(actual_data_lst)\n",
    "\n",
    "    # Assign column headers\n",
    "    df.columns = combined_header\n",
    "\n",
    "    # Add in the station name\n",
    "    stn_name = weather_file.split('.')[0]\n",
    "    df['station'] = stn_name\n",
    "    \n",
    "    # Add latitude and longitude\n",
    "    df['lat'] = lat\n",
    "    df['lon'] = lon\n",
    "    \n",
    "    print('{} processed successfully'.format(stn_name))\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aberporth processed successfully\n",
      "armagh processed successfully\n",
      "ballypatrick processed successfully\n",
      "bradford processed successfully\n",
      "braemar processed successfully\n",
      "camborne processed successfully\n",
      "cambridge processed successfully\n",
      "cardiff processed successfully\n",
      "chivenor processed successfully\n",
      "cwmystwyth processed successfully\n",
      "dunstaffnage processed successfully\n",
      "durham processed successfully\n",
      "eastbourne processed successfully\n",
      "eskdalemuir processed successfully\n",
      "heathrow processed successfully\n",
      "hurn processed successfully\n",
      "lerwick processed successfully\n",
      "leuchars processed successfully\n",
      "lowestoft processed successfully\n",
      "manston processed successfully\n",
      "nairn processed successfully\n",
      "newtonrigg processed successfully\n",
      "oxford processed successfully\n",
      "paisley processed successfully\n",
      "ringway processed successfully\n",
      "rossonwye processed successfully\n",
      "shawbury processed successfully\n",
      "sheffield processed successfully\n",
      "southampton processed successfully\n",
      "stornoway processed successfully\n",
      "suttonbonington processed successfully\n",
      "tiree processed successfully\n",
      "valley processed successfully\n",
      "waddington processed successfully\n",
      "whitby processed successfully\n",
      "wickairport processed successfully\n",
      "yeovilton processed successfully\n"
     ]
    }
   ],
   "source": [
    "# Process the weather data files and store these dataframes as a list\n",
    "weather_df_lst = [load_and_proc_weather_file(weatherfile) for weatherfile in weather_file_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yyyy</th>\n",
       "      <th>mm</th>\n",
       "      <th>tmax degC</th>\n",
       "      <th>tmin degC</th>\n",
       "      <th>af days</th>\n",
       "      <th>rain mm</th>\n",
       "      <th>sun hours</th>\n",
       "      <th>station</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1941</td>\n",
       "      <td>1</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>74.7</td>\n",
       "      <td>---</td>\n",
       "      <td>aberporth</td>\n",
       "      <td>52.139</td>\n",
       "      <td>-4.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1941</td>\n",
       "      <td>2</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>69.1</td>\n",
       "      <td>---</td>\n",
       "      <td>aberporth</td>\n",
       "      <td>52.139</td>\n",
       "      <td>-4.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1941</td>\n",
       "      <td>3</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>76.2</td>\n",
       "      <td>---</td>\n",
       "      <td>aberporth</td>\n",
       "      <td>52.139</td>\n",
       "      <td>-4.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1941</td>\n",
       "      <td>4</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>33.7</td>\n",
       "      <td>---</td>\n",
       "      <td>aberporth</td>\n",
       "      <td>52.139</td>\n",
       "      <td>-4.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1941</td>\n",
       "      <td>5</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>51.3</td>\n",
       "      <td>---</td>\n",
       "      <td>aberporth</td>\n",
       "      <td>52.139</td>\n",
       "      <td>-4.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38071</th>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>12.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6</td>\n",
       "      <td>59.8</td>\n",
       "      <td>62.5#</td>\n",
       "      <td>yeovilton</td>\n",
       "      <td>51.006</td>\n",
       "      <td>-2.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38072</th>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>9.3*</td>\n",
       "      <td>2.6*</td>\n",
       "      <td>9*</td>\n",
       "      <td>95.7*</td>\n",
       "      <td>59.6*</td>\n",
       "      <td>yeovilton</td>\n",
       "      <td>51.006</td>\n",
       "      <td>-2.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38073</th>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>7.6*</td>\n",
       "      <td>0.8*</td>\n",
       "      <td>16*</td>\n",
       "      <td>76.1*</td>\n",
       "      <td>43.2*</td>\n",
       "      <td>yeovilton</td>\n",
       "      <td>51.006</td>\n",
       "      <td>-2.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38074</th>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>11</td>\n",
       "      <td>61.8</td>\n",
       "      <td>65.6#</td>\n",
       "      <td>yeovilton</td>\n",
       "      <td>51.006</td>\n",
       "      <td>-2.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38075</th>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>11.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>119.6#</td>\n",
       "      <td>yeovilton</td>\n",
       "      <td>51.006</td>\n",
       "      <td>-2.641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38076 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       yyyy  mm tmax degC tmin degC af days rain mm sun hours    station  \\\n",
       "0      1941   1       ---       ---     ---    74.7       ---  aberporth   \n",
       "1      1941   2       ---       ---     ---    69.1       ---  aberporth   \n",
       "2      1941   3       ---       ---     ---    76.2       ---  aberporth   \n",
       "3      1941   4       ---       ---     ---    33.7       ---  aberporth   \n",
       "4      1941   5       ---       ---     ---    51.3       ---  aberporth   \n",
       "...     ...  ..       ...       ...     ...     ...       ...        ...   \n",
       "38071  2020  11      12.8       5.7       6    59.8     62.5#  yeovilton   \n",
       "38072  2020  12      9.3*      2.6*      9*   95.7*     59.6*  yeovilton   \n",
       "38073  2021   1      7.6*      0.8*     16*   76.1*     43.2*  yeovilton   \n",
       "38074  2021   2       9.5       2.4      11    61.8     65.6#  yeovilton   \n",
       "38075  2021   3      11.7       2.8       9    27.8    119.6#  yeovilton   \n",
       "\n",
       "          lat     lon  \n",
       "0      52.139  -4.570  \n",
       "1      52.139  -4.570  \n",
       "2      52.139  -4.570  \n",
       "3      52.139  -4.570  \n",
       "4      52.139  -4.570  \n",
       "...       ...     ...  \n",
       "38071  51.006  -2.641  \n",
       "38072  51.006  -2.641  \n",
       "38073  51.006  -2.641  \n",
       "38074  51.006  -2.641  \n",
       "38075  51.006  -2.641  \n",
       "\n",
       "[38076 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat them together for further pre-procesing and cleaning\n",
    "weather_df = pd.concat(weather_df_lst)\n",
    "weather_df = weather_df.reset_index(drop = True)\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8987     Site\n",
       "24390    Site\n",
       "29780    Site\n",
       "Name: yyyy, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The year field should only be 4 digits and be integer\n",
    "\n",
    "# Upon investigation, there are cases where Site closed takes up a row of data, we will need to clean this first\n",
    "weather_df['yyyy'][weather_df['yyyy'].apply(lambda x: len(re.findall('\\d{4}',x)) ==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows where year is equal to site\n",
    "weather_df = weather_df[weather_df['yyyy'] != 'Site']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angsi\\anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Cleaning the year column\n",
    "weather_df['yyyy'] = weather_df['yyyy'].apply(lambda x: int(re.findall('\\d{4}',x)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angsi\\anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Clean the mm column\n",
    "weather_df['mm'] = weather_df['mm'].apply(lambda x: int(re.findall('\\d{1,2}',x)[0]) if len(re.findall('\\d{1,2}',x)) > 0 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a regex to file the digits with decimal places\n",
    "regex = re.compile('\\-?\\d+\\.*\\d*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angsi\\anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmax degC processed successfully\n",
      "tmin degC processed successfully\n",
      "af days processed successfully\n",
      "rain mm processed successfully\n",
      "sun hours processed successfully\n"
     ]
    }
   ],
   "source": [
    "# Clean each of the following columns accordingly\n",
    "num_cols = ['tmax degC', 'tmin degC', 'af days', 'rain mm', 'sun hours']\n",
    "for num_col in num_cols:\n",
    "    weather_df[num_col] = weather_df[num_col].apply(lambda x: float(re.findall(regex, str(x))[0]) if len(re.findall(regex, str(x))) > 0 else np.nan)\n",
    "    print('{} processed successfully'.format(num_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yyyy</th>\n",
       "      <th>mm</th>\n",
       "      <th>tmax degC</th>\n",
       "      <th>tmin degC</th>\n",
       "      <th>af days</th>\n",
       "      <th>rain mm</th>\n",
       "      <th>sun hours</th>\n",
       "      <th>station</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1942</td>\n",
       "      <td>1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>aberporth</td>\n",
       "      <td>52.139</td>\n",
       "      <td>-4.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1942</td>\n",
       "      <td>2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.8</td>\n",
       "      <td>80.3</td>\n",
       "      <td>aberporth</td>\n",
       "      <td>52.139</td>\n",
       "      <td>-4.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1942</td>\n",
       "      <td>3</td>\n",
       "      <td>9.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>117.9</td>\n",
       "      <td>aberporth</td>\n",
       "      <td>52.139</td>\n",
       "      <td>-4.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1942</td>\n",
       "      <td>4</td>\n",
       "      <td>13.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.5</td>\n",
       "      <td>200.1</td>\n",
       "      <td>aberporth</td>\n",
       "      <td>52.139</td>\n",
       "      <td>-4.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1942</td>\n",
       "      <td>5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.1</td>\n",
       "      <td>215.1</td>\n",
       "      <td>aberporth</td>\n",
       "      <td>52.139</td>\n",
       "      <td>-4.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1942</td>\n",
       "      <td>6</td>\n",
       "      <td>16.2</td>\n",
       "      <td>9.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.3</td>\n",
       "      <td>269.3</td>\n",
       "      <td>aberporth</td>\n",
       "      <td>52.139</td>\n",
       "      <td>-4.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1942</td>\n",
       "      <td>7</td>\n",
       "      <td>17.4</td>\n",
       "      <td>11.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.2</td>\n",
       "      <td>185.0</td>\n",
       "      <td>aberporth</td>\n",
       "      <td>52.139</td>\n",
       "      <td>-4.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1942</td>\n",
       "      <td>8</td>\n",
       "      <td>18.7</td>\n",
       "      <td>12.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.5</td>\n",
       "      <td>141.9</td>\n",
       "      <td>aberporth</td>\n",
       "      <td>52.139</td>\n",
       "      <td>-4.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1942</td>\n",
       "      <td>9</td>\n",
       "      <td>16.4</td>\n",
       "      <td>10.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146.8</td>\n",
       "      <td>129.1</td>\n",
       "      <td>aberporth</td>\n",
       "      <td>52.139</td>\n",
       "      <td>-4.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1942</td>\n",
       "      <td>10</td>\n",
       "      <td>13.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.1</td>\n",
       "      <td>82.1</td>\n",
       "      <td>aberporth</td>\n",
       "      <td>52.139</td>\n",
       "      <td>-4.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1942</td>\n",
       "      <td>11</td>\n",
       "      <td>9.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.8</td>\n",
       "      <td>62.9</td>\n",
       "      <td>aberporth</td>\n",
       "      <td>52.139</td>\n",
       "      <td>-4.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1942</td>\n",
       "      <td>12</td>\n",
       "      <td>9.6</td>\n",
       "      <td>6.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183.9</td>\n",
       "      <td>31.4</td>\n",
       "      <td>aberporth</td>\n",
       "      <td>52.139</td>\n",
       "      <td>-4.570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    yyyy  mm  tmax degC  tmin degC  af days  rain mm  sun hours    station  \\\n",
       "12  1942   1        5.8        2.1      NaN    114.0       58.0  aberporth   \n",
       "13  1942   2        4.2       -0.6      NaN     13.8       80.3  aberporth   \n",
       "14  1942   3        9.7        3.7      NaN     58.0      117.9  aberporth   \n",
       "15  1942   4       13.1        5.3      NaN     42.5      200.1  aberporth   \n",
       "16  1942   5       14.0        6.9      NaN    101.1      215.1  aberporth   \n",
       "17  1942   6       16.2        9.9      NaN      2.3      269.3  aberporth   \n",
       "18  1942   7       17.4       11.3      NaN     70.2      185.0  aberporth   \n",
       "19  1942   8       18.7       12.3      NaN     78.5      141.9  aberporth   \n",
       "20  1942   9       16.4       10.7      NaN    146.8      129.1  aberporth   \n",
       "21  1942  10       13.1        8.2      NaN    131.1       82.1  aberporth   \n",
       "22  1942  11        9.2        4.6      NaN     19.8       62.9  aberporth   \n",
       "23  1942  12        9.6        6.2      NaN    183.9       31.4  aberporth   \n",
       "\n",
       "       lat     lon  \n",
       "12  52.139  -4.570  \n",
       "13  52.139  -4.570  \n",
       "14  52.139  -4.570  \n",
       "15  52.139  -4.570  \n",
       "16  52.139  -4.570  \n",
       "17  52.139  -4.570  \n",
       "18  52.139  -4.570  \n",
       "19  52.139  -4.570  \n",
       "20  52.139  -4.570  \n",
       "21  52.139  -4.570  \n",
       "22  52.139  -4.570  \n",
       "23  52.139  -4.570  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do some random checks\n",
    "weather_df[(weather_df['yyyy'] == 1942) & (weather_df['station'] == 'aberporth')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angsi\\anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\angsi\\anaconda3\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Clean lat and lon\n",
    "weather_df['lat'] = weather_df['lat'].astype(float)\n",
    "weather_df['lon'] = weather_df['lon'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export for Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to proc_data for further analysis\n",
    "proc_data_path = '..\\proc_data\\weather'\n",
    "\n",
    "weather_df.to_csv(os.path.join(proc_data_path,'weather.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
